---
title: "Longitudinal Single-Level Regression"
format:
  live-html:
    css: 
      - exams/webex.css
    include-after-body: exams/webex.js
webr:
  packages:
    - dplyr
    - ggplot2
    - haven
toc: true    
---

{{< include _extensions/r-wasm/live/_knitr.qmd >}}

## Grundidee
Mehrebenenregressionsmodelle (auch Multi-Level-Modelle, Hierachische Modelle oder Mixed-Effects-Modelle) sind ein mächtiges Werkzeug zur Modellierung von Daten, die auf mehreren Ebenen genested (geclusterd) organisiert sind. Diese Cluster können etwa Schülerinnen und Schüler in Klassen sein oder Messwiederholungen in Merkmalsträgern. Die Grundidee der Modellierung längsschnittlicher Daten mit Mehrebenenmodellen besteht darin, sowohl die Variation innerhalb der Cluster (=Merkmalsträger) als auch zwischen den Clustern zu modellieren. Die Variation zischen den Clustern (auch Level-2 Effekte oder Random Effekte) werden dabei als »Streuung von Regressionsparametern« konzeptualisiert. Damit die Zeit in diesem Modellen als Prädiktor berücksichtigt werden kann, müssen die Daten in einer bestimmten Weise strukturiert werden die oft »long data« genannt wird (siehe @tbl-long-data).


| ID | Mathe Klasse 1 | Mathe Klasse 2 | Mathe Klasse 3 |
|----------------|----------------|----------------|----------------|
| A              | 463            | 475            | 501            |
| B              | 499            | 503            | 505            |
| C              | 360            | 365            | 372            |

: »Wide data« {#tbl-wide-data}


| ID | Mathe | Klasse |
|----------------|-------|--------|
| A              | 463   | 1      |
| A              | 475   | 2      |
| A              | 501   | 3      |
| B              | 499   | 1      |
| B              | 503   | 2      |
| B              | 505   | 3      |
| C              | 360   | 1      |
| C              | 365   | 2      |
| C              | 372   | 3      |
 
: »Long data« {#tbl-long-data}


## Data Wrangling {#sec-prädiktion-differenzen}
Fast jede Statistiksoftware verfügt über mehr oder weniger intuitive Werkzeuge zur Datenaufbereitung. In {{< fa-brands:r-project >>}} sind insbesondere die Pakete `dplyr` und `tidyr` sehr hilfreich. Hier ein Beispiel für die Warangling von "Wide" in "Long" Format:
```{r}
library(haven)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(colorspace)

data_star <- read_sav(
  "https://raw.githubusercontent.com/sammerk/WinterSchoolZH/master/data_star_workshop.sav"
)

data_star_subset <- data_star %>%
  group_by(classID) %>%
  summarize(
    MathClassMeanCl0 = mean(gktmathss, na.rm = T),
    MathClassMeanCl1 = mean(g1tmathss, na.rm = T),
    MathClassMeanCl2 = mean(g2tmathss, na.rm = T),
    MathClassMeanCl3 = mean(g3tmathss, na.rm = T),
    MathClassMeanCl4 = mean(g4tmathss, na.rm = T),
    PropFreeLunchCl0 = mean(ifelse(gkfreelunch == 1, 1, 0), na.rm = T),
    PropFreeLunchCl1 = mean(ifelse(g1freelunch == 1, 1, 0), na.rm = T),
    PropFreeLunchCl2 = mean(ifelse(g2freelunch == 1, 1, 0), na.rm = T),
    PropFreeLunchCl3 = mean(ifelse(g3freelunch == 1, 1, 0), na.rm = T),
    ClasssizeCl0 = mean(gkclasssize, na.rm = T),
    ClasssizeCl1 = mean(g1classsize, na.rm = T),
    ClasssizeCl2 = mean(g2classsize, na.rm = T),
    ClasssizeCl3 = mean(g3classsize, na.rm = T)
  ) %>%
  ungroup()

data_star_subset_long <- data_star_subset %>%
  # pivoting
  pivot_longer(
    cols = c(
      starts_with("MathClassMean"),
      starts_with("PropFreeLunch"),
      starts_with("Classsize")
    ),
    names_to = "variable",
    values_to = "value"
  ) %>%
  # separating variable names
  mutate(
    time = as.numeric(str_sub(variable, -1, -1)),
    variable = str_sub(variable, 1, -4)
  ) %>%
  # pivot wider in tidy data format  
  pivot_wider(
    names_from = variable,
    values_from = value
  )
```

### Grafische Darstellung
```{r}
data_sample_naomit <- 
  data_star_subset_long %>% 
  na.omit() %>% 
  group_by(classID) %>% 
  mutate(npergroup = n()) %>% 
  ungroup() %>% 
  filter(npergroup == 3) %>% 
  arrange(classID) %>% 
  slice(31:61)

ggplot(data_sample_naomit, aes(x = time, y = MathClassMean)) +
  geom_point(aes(color = as.factor(classID))) +
  stat_smooth(
    aes(color = as.factor(classID)),
    method = "lm",
    se = FALSE,
    linewidth = .4
  ) +
  stat_smooth(
    method = "lm",
    se = FALSE,
    linewidth = 2,
    linetype = "dashed",
    color = "#267326"
  ) +
  scale_color_discrete_qualitative(palette = "Dark3") +
  theme_minimal() +
  theme(legend.position = "none")
```

In Abbildung XX sehen wir die Entwicklung der Mathematik-Klassenmittelwerte über die Zeit, wobei die einzelnen Klassen durch unterschiedliche Farben dargestellt sind und jede Klasse eine eigene Regressionsgerade hat (No Pooling Modell). Die gestrichelte Linie repräsentiert ein lineares Regressionsmodell für alle Datenpunkte (Complete Pooling Modell).

::: {.callout-caution}
Achtung: Die Inferenzstatistik des Complete Pooling Modells bedarf besonderer Aufmerksamkeit. Die »klassische« Berechnung von p-Werten und Konfidenzintervallen setzt eine Unabhängigkeit der Residuen voraus. Diese ist hier aber nicht gegeben, denn z.B. starke Klassen werden etwa tendenziell positive Residuen haben.
:::

Ein Mehrebenenmodell stellt eine Art Kompromiss aus No Pooling und Complete Pooling dar und wird daher auch Partial Poolign Modell genannt. Es lässt zwarfür jeden Merkmalsträger eine individuelle Regressionsgerade zu, berücksichtigt bei deren Wahl aber auch Information aus den anderen Merkmalsträgern (sog. Shrinkage). Die Variation zwischen den einzelnen Klassen kann sich auf alle Parameter (etwa Intercept und/oder Slopes) beziehen (siehe Abbildungen).

```{r}
library(lme4)
# Random Intercept Modell
model_ri <- lmer(MathClassMean ~ time + (1| classID), data = data_sample_naomit)

# Vorhersagen für jede Klasse
predictions <- data_sample_naomit %>%
  mutate(predicted = predict(model_ri))

# Plot mit Random Intercept Modell
ggplot(data_sample_naomit, aes(x = time, y = MathClassMean)) +
  geom_point(aes(color = as.factor(classID))) +
  geom_line(
    data = predictions,
    aes(x = time, y = predicted, color = as.factor(classID)),
    linewidth = 0.7
  ) +
  stat_smooth(method = "lm", se = FALSE, linewidth = 2, linetype = "dashed", color = "#267326") +
  scale_color_discrete_qualitative(palette = "Dark3") +
  theme_minimal() +
  theme(legend.position = "none")

model_rirs <- lmer(MathClassMean ~ time + (1 + time| classID), data = data_sample_naomit)

# Vorhersagen für jede Klasse
predictions_rirs <- data_sample_naomit %>%
  mutate(predicted = predict(model_rirs))

# Plot mit Random Intercept Modell
ggplot(data_sample_naomit, aes(x = time, y = MathClassMean)) +
  geom_point(aes(color = as.factor(classID))) +
  geom_line(
    data = predictions_rirs,
    aes(x = time, y = predicted, color = as.factor(classID)),
    linewidth = 0.7
  ) +
  stat_smooth(method = "lm", se = FALSE, linewidth = 2, linetype = "dashed", color = "#267326") +
  scale_color_discrete_qualitative(palette = "Dark3") +
  theme_minimal() +
  theme(legend.position = "none")
```


Typischerweise baut man längsschnittliche Mehrebenenmodelle Schritt für Schritt auf und testet jeweils, inwiefern weitere Modellfreiehitsgrade (z.B. varying Slopes) zu zusätzlicher Varianzaufklärung führen.
