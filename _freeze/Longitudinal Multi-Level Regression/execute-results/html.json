{
  "hash": "6b78308c8d5bfdab472b56b9feb4f149",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Longitudinal Multi-Level Regression\"\nformat:\n  live-html:\n    css: \n      - exams/webex.css\n    include-after-body: exams/webex.js\nwebr:\n  packages:\n    - dplyr\n    - ggplot2\n    - haven\ntoc: true    \nlightbox: true\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n## Grundidee\nMehrebenenregressionsmodelle (auch Multi-Level-Modelle, Hierachische Modelle oder Mixed-Effects-Modelle) sind ein mächtiges Werkzeug zur Modellierung von Daten, die auf mehreren Ebenen genested (geclusterd) organisiert sind. Diese Cluster können etwa Schülerinnen und Schüler in Klassen sein oder Messwiederholungen in Merkmalsträgern. Die Grundidee der Modellierung längsschnittlicher Daten mit Mehrebenenmodellen besteht darin, sowohl die Variation innerhalb der Cluster (=Merkmalsträger) als auch zwischen den Clustern zu modellieren. Die Variation zischen den Clustern (auch Level-2 Effekte oder Random Effekte) werden dabei als »Streuung von Regressionsparametern« konzeptualisiert. Damit die Zeit in diesem Modellen als Prädiktor berücksichtigt werden kann, müssen die Daten in einer bestimmten Weise strukturiert werden die oft »long data« genannt wird (siehe @tbl-long-data).\n\n\n| ID | Mathe Klasse 1 | Mathe Klasse 2 | Mathe Klasse 3 |\n|----------------|----------------|----------------|----------------|\n| A              | 463            | 475            | 501            |\n| B              | 499            | 503            | 505            |\n| C              | 360            | 365            | 372            |\n\n: »Wide data« {#tbl-wide-data}\n\n\n| ID | Mathe | Klasse |\n|----------------|-------|--------|\n| A              | 463   | 1      |\n| A              | 475   | 2      |\n| A              | 501   | 3      |\n| B              | 499   | 1      |\n| B              | 503   | 2      |\n| B              | 505   | 3      |\n| C              | 360   | 1      |\n| C              | 365   | 2      |\n| C              | 372   | 3      |\n \n: »Long data« {#tbl-long-data}\n\n\n## Data Wrangling {#sec-prädiktion-differenzen}\nFast jede Statistiksoftware verfügt über mehr oder weniger intuitive Werkzeuge zur Datenaufbereitung. In {{< iconify fa-brands:r-project style=\"color:#267326;\" >}} sind insbesondere die Pakete `dplyr` und `tidyr` sehr hilfreich. Hier ein Beispiel für das Wrangling von \"Wide\" in \"Long\" Format:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(colorspace)\n\ndata_star <- read_sav(\n  \"https://raw.githubusercontent.com/sammerk/WinterSchoolZH/master/data_star_workshop.sav\"\n)\n\ndata_star_subset <- data_star %>%\n  group_by(classID) %>%\n  summarize(\n    MathClassMeanCl0 = mean(gktmathss, na.rm = T),\n    MathClassMeanCl1 = mean(g1tmathss, na.rm = T),\n    MathClassMeanCl2 = mean(g2tmathss, na.rm = T),\n    MathClassMeanCl3 = mean(g3tmathss, na.rm = T),\n    MathClassMeanCl4 = mean(g4tmathss, na.rm = T),\n    PropFreeLunchCl0 = mean(ifelse(gkfreelunch == 1, 1, 0), na.rm = T),\n    PropFreeLunchCl1 = mean(ifelse(g1freelunch == 1, 1, 0), na.rm = T),\n    PropFreeLunchCl2 = mean(ifelse(g2freelunch == 1, 1, 0), na.rm = T),\n    PropFreeLunchCl3 = mean(ifelse(g3freelunch == 1, 1, 0), na.rm = T),\n    ClasssizeCl0 = mean(gkclasssize, na.rm = T),\n    ClasssizeCl1 = mean(g1classsize, na.rm = T),\n    ClasssizeCl2 = mean(g2classsize, na.rm = T),\n    ClasssizeCl3 = mean(g3classsize, na.rm = T)\n  ) %>%\n  ungroup()\n\ndata_star_subset_long <- data_star_subset %>%\n  # pivoting\n  pivot_longer(\n    cols = c(\n      starts_with(\"MathClassMean\"),\n      starts_with(\"PropFreeLunch\"),\n      starts_with(\"Classsize\")\n    ),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) %>%\n  # separating variable names\n  mutate(\n    time = as.numeric(str_sub(variable, -1, -1)),\n    variable = str_sub(variable, 1, -4)\n  ) %>%\n  # pivot wider in tidy data format  \n  pivot_wider(\n    names_from = variable,\n    values_from = value\n  )\n```\n:::\n\n\n### Grafische Darstellung\n\n::: {#fig-pooling .cell layout-ncol=\"3\"}\n::: {.cell-output-display}\n![](Longitudinal-Multi-Level-Regression_files/figure-html/fig-pooling-1.png){#fig-pooling-1 width=2100}\n:::\n\n::: {.cell-output-display}\n![](Longitudinal-Multi-Level-Regression_files/figure-html/fig-pooling-2.png){#fig-pooling-2 width=2100}\n:::\n\n::: {.cell-output-display}\n![](Longitudinal-Multi-Level-Regression_files/figure-html/fig-pooling-3.png){#fig-pooling-3 width=2100}\n:::\n\nComplete Pooling vs. No Pooling (links), Complete Pooling vs. Partial Pooling (mitte und rechts)\n:::\n\n\nIn Abbildung @fig-pooling-1 sehen wir die Entwicklung der Mathematik-Klassenmittelwerte über die Zeit, wobei die einzelnen Klassen durch unterschiedliche Farben dargestellt sind und jede Klasse eine eigene Regressionsgerade hat (No Pooling Modell). Die gestrichelte Linie repräsentiert ein lineares Regressionsmodell für alle Datenpunkte (Complete Pooling Modell).\n\n::: {.callout-caution}\nAchtung: Die Inferenzstatistik des Complete Pooling Modells bedarf besonderer Aufmerksamkeit. Die »klassische« Berechnung von p-Werten und Konfidenzintervallen setzt eine Unabhängigkeit der Residuen voraus. Diese ist hier aber nicht gegeben, denn z.B. starke Klassen werden etwa tendenziell positive Residuen haben.\n:::\n\nEin Mehrebenenmodell stellt eine Art Kompromiss aus No Pooling und Complete Pooling dar und wird daher auch Partial Pooling Modell genannt. Es lässt zwarfür jeden Merkmalsträger eine individuelle Regressionsgerade zu, berücksichtigt bei deren Wahl aber auch Information aus den anderen Merkmalsträgern (sog. Shrinkage). Die Variation zwischen den einzelnen Klassen kann sich auf alle Parameter beziehen. Etwa die Intercepts (siehe @fig-pooling-2) oder (Intercepts und) Slopes (siehe @fig-pooling-3).\n\n### Modellierung\nDie Modellierung längsschnittlicher Daten mit Mehrebenenmodellen erfolgt typischerweise in mehreren Schritten. Zunächst wird oft ein sogenanntes varying Intercept Mdoel geschätzt:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmod0 <- lmer(MathClassMean ~ time + (1 | classID), data = data_sample_naomit)\nsummary(mod0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: MathClassMean ~ time + (1 | classID)\n   Data: data_sample_naomit\n\nREML criterion at convergence: 254.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5452 -0.4852  0.1162  0.6143  1.2839 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n classID  (Intercept) 449.7    21.21   \n Residual             214.5    14.65   \nNumber of obs: 30, groups:  classID, 10\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  499.317      9.748   51.22\ntime          38.640      3.275   11.80\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime -0.672\n```\n\n\n:::\n:::\n\n\nHierbei wird die Mathematikleistung als Funktion der Zeit modelliert, wobei für jede Klasse ein eigener Intercept in abhängigkeit der anderen Intercepts geschätzt wird (partial pooling). Dies ermöglicht es, die durchschnittliche Entwicklung der Mathematikleistung über die Zeit zu erfassen, während gleichzeitig die Unterschiede zwischen den Klassen berücksichtigt werden.\n\nAls nächstes kann ein varying Intercept and Slope Modell geschätzt werden:\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- lmer(MathClassMean ~ time + (1 + time | classID), data = data_sample_naomit)\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: MathClassMean ~ time + (1 + time | classID)\n   Data: data_sample_naomit\n\nREML criterion at convergence: 249.3\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.21082 -0.64126  0.08962  0.49495  1.68887 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n classID  (Intercept) 258.24   16.07         \n          time         93.32    9.66    -0.25\n Residual             126.14   11.23         \nNumber of obs: 30, groups:  classID, 10\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  499.317      7.434  67.171\ntime          38.640      3.955   9.771\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime -0.559\n```\n\n\n:::\n:::\n\n\nUnd diese beiden Modelle gegeneinander getestet werden:\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod0, mod1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrefitting model(s) with ML (instead of REML)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: data_sample_naomit\nModels:\nmod0: MathClassMean ~ time + (1 | classID)\nmod1: MathClassMean ~ time + (1 + time | classID)\n     npar    AIC    BIC  logLik -2*log(L)  Chisq Df Pr(>Chisq)  \nmod0    4 271.98 277.58 -131.99    263.98                       \nmod1    6 271.25 279.66 -129.62    259.25 4.7261  2    0.09413 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}